{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ir3_y1E0x8A",
        "outputId": "3039d01a-6f93-4e63-bf2c-988a42c39913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.0)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from wordcloud) (11.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from wordcloud) (3.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (3.2.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk scikit-learn pandas flask pyngrok joblib wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import re\n",
        "# import string\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import nltk\n",
        "# from nltk.tokenize import word_tokenize\n",
        "# from nltk.corpus import stopwords\n",
        "# from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "# import requests\n",
        "# import tarfile\n",
        "# from io import BytesIO\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.feature_selection import SelectKBest, chi2\n",
        "# from sklearn.svm import LinearSVC\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# import joblib\n",
        "# from flask import Flask, request, render_template_string, jsonify\n",
        "# from pyngrok import ngrok\n",
        "# import threading\n",
        "# import time\n",
        "# import psutil\n",
        "# import shutil\n",
        "# import logging\n",
        "\n",
        "# # Set up logging\n",
        "# logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# # Download NLTK data\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('omw-1.4')\n",
        "# nltk.download('punkt_tab')\n",
        "\n",
        "# # Download and extract dataset\n",
        "# url = \"http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\"\n",
        "# output_csv = \"data_set.csv\"\n",
        "# print(\"Downloading dataset...\")\n",
        "# response = requests.get(url)\n",
        "# if response.status_code != 200:\n",
        "#     raise Exception(\"Failed to download the dataset\")\n",
        "# print(\"Extracting dataset...\")\n",
        "# tar = tarfile.open(fileobj=BytesIO(response.content), mode=\"r:gz\")\n",
        "# tar.extractall(path=\"movie_reviews\")\n",
        "# tar.close()\n",
        "\n",
        "# # Load reviews and labels\n",
        "# reviews = []\n",
        "# labels = []\n",
        "# base_dir = \"movie_reviews/txt_sentoken\"\n",
        "# pos_dir = os.path.join(base_dir, \"pos\")\n",
        "# for filename in os.listdir(pos_dir):\n",
        "#     if filename.endswith(\".txt\"):\n",
        "#         with open(os.path.join(pos_dir, filename), \"r\", encoding=\"utf-8\") as file:\n",
        "#             review = file.read().strip()\n",
        "#             reviews.append(review)\n",
        "#             labels.append(1)\n",
        "# neg_dir = os.path.join(base_dir, \"neg\")\n",
        "# for filename in os.listdir(neg_dir):\n",
        "#     if filename.endswith(\".txt\"):\n",
        "#         with open(os.path.join(neg_dir, filename), \"r\", encoding=\"utf-8\") as file:\n",
        "#             review = file.read().strip()\n",
        "#             reviews.append(review)\n",
        "#             labels.append(0)\n",
        "\n",
        "# # Create CSV file\n",
        "# print(\"Creating CSV file...\")\n",
        "# data = {\"review\": reviews, \"sentiment\": labels}\n",
        "# df = pd.DataFrame(data)\n",
        "# df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
        "# print(f\"Dataset saved to {output_csv}\")\n",
        "# shutil.rmtree(\"movie_reviews\")\n",
        "# print(\"Cleaned up temporary files\")\n",
        "\n",
        "# # Text preprocessing functions\n",
        "# def remove_punctuation(text):\n",
        "#     return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# def normalize_text(text):\n",
        "#     normalization_map = {\n",
        "#         'u': 'you',\n",
        "#         'ur': 'your',\n",
        "#         'r': 'are',\n",
        "#         'b4': 'before',\n",
        "#         'gr8': 'great',\n",
        "#         'gud': 'good',\n",
        "#         'pls': 'please',\n",
        "#         'plz': 'please',\n",
        "#         'thx': 'thanks',\n",
        "#         'l8r': 'later',\n",
        "#         'msg': 'message',\n",
        "#         'btw': 'by the way',\n",
        "#         'idk': 'i do not know',\n",
        "#         'imo': 'in my opinion'\n",
        "#     }\n",
        "#     words = text.split()\n",
        "#     return ' '.join([normalization_map.get(word, word) for word in words])\n",
        "\n",
        "# def stem_text(text):\n",
        "#     stemmer = PorterStemmer()\n",
        "#     stop_words = set(stopwords.words('english')) - {'was'}\n",
        "#     tokens = text.split()\n",
        "#     return ' '.join([stemmer.stem(token) for token in tokens if token not in stop_words])\n",
        "\n",
        "# def remove_word_duplicates(text):\n",
        "#     words = word_tokenize(text)\n",
        "#     seen = set()\n",
        "#     new_words = []\n",
        "#     for word in words:\n",
        "#         if word.lower() not in seen:\n",
        "#             seen.add(word.lower())\n",
        "#             new_words.append(word)\n",
        "#     return ' '.join(new_words)\n",
        "\n",
        "# def preprocess_text(text):\n",
        "#     text = text.lower()\n",
        "#     text = remove_punctuation(text)\n",
        "#     text = normalize_text(text)\n",
        "#     text = ' '.join([word for word in text.split() if word not in (set(stopwords.words('english')) - {'was'})])\n",
        "#     text = remove_word_duplicates(text)\n",
        "#     lemmatizer = WordNetLemmatizer()\n",
        "#     text = ' '.join([lemmatizer.lemmatize(word) for word in nltk.word_tokenize(text)])\n",
        "#     text = stem_text(text)\n",
        "#     return text\n",
        "\n",
        "# # Preprocess data\n",
        "# df['review'] = df['review'].apply(preprocess_text)\n",
        "# df['sentiment'] = df['sentiment'].astype(str)\n",
        "\n",
        "# # Split data\n",
        "# X = df['review'].astype(str).tolist()\n",
        "# y = df['sentiment']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Vectorize and select features\n",
        "# vectorizer = TfidfVectorizer(max_features=10000)\n",
        "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "# X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# selector = SelectKBest(chi2, k=5000)\n",
        "# X_train_tfidf = selector.fit_transform(X_train_tfidf, y_train)\n",
        "# X_test_tfidf = selector.transform(X_test_tfidf)\n",
        "\n",
        "# # Train model\n",
        "# model = LinearSVC(C=1, random_state=42, class_weight='balanced', max_iter=10000)\n",
        "# model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# # Evaluate model\n",
        "# y_pred = model.predict(X_test_tfidf)\n",
        "# print(f\"Test Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "\n",
        "# # Debug vocabulary and feature weights\n",
        "# print(\"Vocabulary contains 'good':\", \"good\" in vectorizer.vocabulary_)\n",
        "# print(\"Vocabulary contains 'movi':\", \"movi\" in vectorizer.vocabulary_)\n",
        "# selected_features = vectorizer.get_feature_names_out()[selector.get_support()]\n",
        "# print(\"Selected features contain 'good':\", \"good\" in selected_features)\n",
        "# print(\"Selected features contain 'movi':\", \"movi\" in selected_features)\n",
        "# feature_weights = model.coef_[0]\n",
        "# feature_importance = dict(zip(selected_features, feature_weights))\n",
        "# print(\"Weight for 'good':\", feature_importance.get(\"good\", \"Not found\"))\n",
        "# print(\"Weight for 'movi':\", feature_importance.get(\"movi\", \"Not found\"))\n",
        "\n",
        "# # Save model, vectorizer, and selector\n",
        "# joblib.dump(model, 'linear_svc_model.pkl')\n",
        "# joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
        "# joblib.dump(selector, 'chi2_selector.pkl')\n",
        "# print(\"Model, vectorizer, and selector saved.\")\n",
        "\n",
        "# # HTML template\n",
        "# html_template = \"\"\"\n",
        "# <!DOCTYPE html>\n",
        "# <html lang=\"en\">\n",
        "# <head>\n",
        "#     <meta charset=\"UTF-8\">\n",
        "#     <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "#     <title>Sentiment Analysis</title>\n",
        "#     <link rel=\"stylesheet\" href=\"/static/style.css\">\n",
        "# </head>\n",
        "# <body>\n",
        "#     <div class=\"header\">\n",
        "#         <h2>Sentiment Analysis of Movie Reviews</h2>\n",
        "#     </div>\n",
        "#     <div class=\"parent\">\n",
        "#         <div class=\"collection\">\n",
        "#             <p>Please enter your text in English for analysis</p>\n",
        "#             <form onsubmit=\"analyzeReview(event)\">\n",
        "#                 <textarea id=\"reviewInput\" placeholder=\"Type here...\" cols=\"70\" rows=\"10\"></textarea>\n",
        "#                 <button type=\"submit\">Analyze</button>\n",
        "#             </form>\n",
        "#             <div id=\"result\" class=\"result\"></div>\n",
        "#             <div id=\"processed\" class=\"processed\"></div>\n",
        "#         </div>\n",
        "#     </div>\n",
        "\n",
        "#     <script>\n",
        "#         // Auto-resize textarea\n",
        "#         const textarea = document.getElementById('reviewInput');\n",
        "#         textarea.addEventListener('input', function () {\n",
        "#             this.style.height = 'auto';\n",
        "#             this.style.height = `${this.scrollHeight}px`;\n",
        "#         });\n",
        "\n",
        "#         // Handle form submission and send request to backend\n",
        "#         async function analyzeReview(event) {\n",
        "#             event.preventDefault();\n",
        "#             const review = document.getElementById('reviewInput').value.trim();\n",
        "#             const resultDiv = document.getElementById('result');\n",
        "#             const processedDiv = document.getElementById('processed');\n",
        "\n",
        "#             if (!review) {\n",
        "#                 resultDiv.innerHTML = '<p class=\"error\">Please enter a review.</p>';\n",
        "#                 processedDiv.innerHTML = '';\n",
        "#                 return;\n",
        "#             }\n",
        "\n",
        "#             resultDiv.innerHTML = '<p>Analyzing...</p>';\n",
        "#             processedDiv.innerHTML = '';\n",
        "\n",
        "#             try {\n",
        "#                 const response = await fetch('/analyze', {\n",
        "#                     method: 'POST',\n",
        "#                     headers: {\n",
        "#                         'Content-Type': 'application/json',\n",
        "#                     },\n",
        "#                     body: JSON.stringify({ review: review }),\n",
        "#                 });\n",
        "\n",
        "#                 const data = await response.json();\n",
        "\n",
        "#                 if (response.ok) {\n",
        "#                     resultDiv.innerHTML = `<p class=\"success\">Sentiment: ${data.sentiment}</p>`;\n",
        "#                     processedDiv.innerHTML = `<p class=\"processed-text\"><strong>Processed Review:</strong> ${data.processed_text}</p>`;\n",
        "#                 } else {\n",
        "#                     resultDiv.innerHTML = `<p class=\"error\">Error: ${data.error}</p>`;\n",
        "#                     processedDiv.innerHTML = '';\n",
        "#                 }\n",
        "#             } catch (error) {\n",
        "#                 resultDiv.innerHTML = '<p class=\"error\">Error: Unable to connect to the server.</p>';\n",
        "#                 processedDiv.innerHTML = '';\n",
        "#             }\n",
        "#         }\n",
        "#     </script>\n",
        "# </body>\n",
        "# </html>\n",
        "# \"\"\"\n",
        "\n",
        "# # CSS content\n",
        "# css_content = \"\"\"\n",
        "# * {\n",
        "#     margin: 0;\n",
        "#     padding: 0;\n",
        "#     box-sizing: border-box;\n",
        "# }\n",
        "\n",
        "# body {\n",
        "#     background-color: #ffd9e8;\n",
        "#     color: #333;\n",
        "#     font-family: Arial, sans-serif;\n",
        "#     font-size: 17px;\n",
        "# }\n",
        "\n",
        "# .header {\n",
        "#     width: 100%;\n",
        "#     height: 100px;\n",
        "#     background-color: #F564A9;\n",
        "#     padding-top: 25px;\n",
        "# }\n",
        "\n",
        "# .header h2 {\n",
        "#     text-transform: capitalize;\n",
        "#     font-size: 33px;\n",
        "#     text-align: center;\n",
        "#     color: white;\n",
        "# }\n",
        "\n",
        "# .parent {\n",
        "#     margin-top: 50px;\n",
        "#     display: flex;\n",
        "#     align-items: center;\n",
        "#     justify-content: center;\n",
        "# }\n",
        "\n",
        "# .collection {\n",
        "#     background-color: #F564A9;\n",
        "#     width: 90%;\n",
        "#     max-width: 600px;\n",
        "#     min-height: 400px;\n",
        "#     display: flex;\n",
        "#     flex-direction: column;\n",
        "#     justify-content: center;\n",
        "#     align-items: center;\n",
        "#     border-radius: 20px;\n",
        "#     padding: 20px;\n",
        "#     box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
        "# }\n",
        "\n",
        "# .collection p {\n",
        "#     text-transform: capitalize;\n",
        "#     font-size: 20px;\n",
        "#     text-align: center;\n",
        "#     color: white;\n",
        "#     margin-bottom: 20px;\n",
        "# }\n",
        "\n",
        "# .collection textarea {\n",
        "#     background-color: #ffd9e8;\n",
        "#     margin-top: 10px;\n",
        "#     width: 100%;\n",
        "#     min-height: 150px;\n",
        "#     resize: vertical;\n",
        "#     border: none;\n",
        "#     border-radius: 10px;\n",
        "#     padding: 15px;\n",
        "#     font-size: 17px;\n",
        "#     color: #333;\n",
        "#     box-sizing: border-box;\n",
        "# }\n",
        "\n",
        "# .collection textarea::placeholder {\n",
        "#     color: #c90865;\n",
        "#     text-align: left;\n",
        "#     opacity: 1;\n",
        "# }\n",
        "\n",
        "# .collection button {\n",
        "#     width: 150px;\n",
        "#     height: 40px;\n",
        "#     border: none;\n",
        "#     border-radius: 10px;\n",
        "#     font-size: 20px;\n",
        "#     color: #c90865;\n",
        "#     background-color: #ffd9e8;\n",
        "#     cursor: pointer;\n",
        "#     transition: background-color 0.3s;\n",
        "#     margin-top: 20px;\n",
        "# }\n",
        "\n",
        "# .result {\n",
        "#     margin-top: 20px;\n",
        "#     text-align: center;\n",
        "#     min-height: 30px;\n",
        "# }\n",
        "\n",
        "# .processed {\n",
        "#     margin-top: 10px;\n",
        "#     text-align: center;\n",
        "#     min-height: 30px;\n",
        "# }\n",
        "\n",
        "# .processed-text {\n",
        "#     color: #fff;\n",
        "#     font-size: 16px;\n",
        "#     background-color: #c90865;\n",
        "#     padding: 10px;\n",
        "#     border-radius: 5px;\n",
        "#     word-wrap: break-word;\n",
        "#     max-width: 100%;\n",
        "# }\n",
        "\n",
        "# .success {\n",
        "#     color: #28a745;\n",
        "#     font-weight: bold;\n",
        "# }\n",
        "\n",
        "# .error {\n",
        "#     color: #dc3545;\n",
        "#     font-weight: bold;\n",
        "# }\n",
        "# \"\"\"\n",
        "\n",
        "# # Save CSS file\n",
        "# os.makedirs('static', exist_ok=True)\n",
        "# with open('static/style.css', 'w') as f:\n",
        "#     f.write(css_content)\n",
        "\n",
        "# # Initialize Flask app\n",
        "# app = Flask(__name__)\n",
        "\n",
        "# # Load model, vectorizer, and selector\n",
        "# model = joblib.load('linear_svc_model.pkl')\n",
        "# vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
        "# selector = joblib.load('chi2_selector.pkl')\n",
        "\n",
        "# # Flask routes\n",
        "# @app.route('/', methods=['GET'])\n",
        "# def index():\n",
        "#     return render_template_string(html_template)\n",
        "\n",
        "# @app.route('/analyze', methods=['POST'])\n",
        "# def analyze():\n",
        "#     data = request.get_json()\n",
        "#     review = data.get('review', '').strip()\n",
        "#     logging.info(f\"Received review: {review}\")\n",
        "#     if not review:\n",
        "#         return jsonify({'error': 'Please enter a review.'}), 400\n",
        "#     processed_text = preprocess_text(review)\n",
        "#     logging.info(f\"Processed text: {processed_text}\")\n",
        "#     text_tfidf = vectorizer.transform([processed_text])\n",
        "#     text_tfidf_selected = selector.transform(text_tfidf)\n",
        "#     prediction = model.predict(text_tfidf_selected)[0]\n",
        "#     logging.info(f\"Prediction: {prediction}\")\n",
        "#     sentiment = \"Positive üòÑ‚úîÔ∏è\" if prediction == \"1\" else \"Negative üòî‚ùå\"\n",
        "#     return jsonify({\n",
        "#         'sentiment': sentiment,\n",
        "#         'processed_text': processed_text\n",
        "#     })\n",
        "\n",
        "# # Function to kill process on port\n",
        "# def kill_process_on_port(port):\n",
        "#     for proc in psutil.process_iter(['pid', 'name']):\n",
        "#         try:\n",
        "#             for conn in proc.connections(kind='inet'):\n",
        "#                 if conn.laddr.port == port:\n",
        "#                     print(f\"Killing process {proc.pid} on port {port}\")\n",
        "#                     proc.kill()\n",
        "#                     return True\n",
        "#         except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n",
        "#             continue\n",
        "#     return False\n",
        "\n",
        "# # Start ngrok and Flask server\n",
        "# ngrok.set_auth_token('2x9G2X34klXZC2VDcx4AFxbvAPm_2DCdLrALRo27kMQxwq55u')\n",
        "# PORT = 5001\n",
        "# try:\n",
        "#     ngrok.kill()\n",
        "#     kill_process_on_port(PORT)\n",
        "#     public_url = ngrok.connect(PORT).public_url\n",
        "#     print(f\"Public URL: {public_url}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Error starting ngrok: {e}\")\n",
        "#     print(\"Please ensure no other ngrok sessions are active and try again. Check https://dashboard.ngrok.com/agents\")\n",
        "\n",
        "# def run_app():\n",
        "#     print(f\"Starting Flask server on port {PORT}...\")\n",
        "#     app.run(host='0.0.0.0', port=PORT, use_reloader=False)\n",
        "#     print(f\"Flask server running on port {PORT}.\")\n",
        "\n",
        "# threading.Thread(target=run_app, daemon=True).start()\n",
        "\n",
        "# # Check server status\n",
        "# time.sleep(2)\n",
        "# try:\n",
        "#     response = requests.get(f\"{public_url}\")\n",
        "#     print(\"Server is up and running!\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Server check failed: {e}\")\n",
        "#     print(\"The Flask server may not have started correctly. Please restart the cell or runtime.\")\n",
        "\n",
        "# # Test specific input\n",
        "# test_review = \"movie was good\"\n",
        "# processed_test = preprocess_text(test_review)\n",
        "# print(f\"Processed test review: {processed_test}\")\n",
        "# test_tfidf = vectorizer.transform([processed_test])\n",
        "# test_tfidf_selected = selector.transform(test_tfidf)\n",
        "# test_prediction = model.predict(test_tfidf_selected)[0]\n",
        "# print(f\"Prediction for 'movie was good': {test_prediction}\")\n",
        "# print(f\"Sentiment: {'Positive üòÑ‚úîÔ∏è' if test_prediction == '1' else 'Negative üòî‚ùå'}\")"
      ],
      "metadata": {
        "id": "p4nLoQBBgewh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import re\n",
        "# import string\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import nltk\n",
        "# from nltk.tokenize import word_tokenize\n",
        "# from nltk.corpus import stopwords\n",
        "# from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "# import requests\n",
        "# import tarfile\n",
        "# from io import BytesIO\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.feature_selection import SelectKBest, chi2\n",
        "# from sklearn.svm import LinearSVC\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# import joblib\n",
        "# from flask import Flask, request, render_template_string, jsonify\n",
        "# from pyngrok import ngrok\n",
        "# import threading\n",
        "# import time\n",
        "# import psutil\n",
        "# import shutil\n",
        "# import logging\n",
        "\n",
        "# # Set up logging\n",
        "# logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# # Download NLTK data\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('omw-1.4')\n",
        "# nltk.download('punkt_tab')\n",
        "\n",
        "# # Download and extract dataset (same as notebook)\n",
        "# url = \"http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\"\n",
        "# output_csv = \"data_set.csv\"\n",
        "# print(\"Downloading dataset...\")\n",
        "# response = requests.get(url)\n",
        "# if response.status_code != 200:\n",
        "#     raise Exception(\"Failed to download the dataset\")\n",
        "# print(\"Extracting dataset...\")\n",
        "# tar = tarfile.open(fileobj=BytesIO(response.content), mode=\"r:gz\")\n",
        "# tar.extractall(path=\"movie_reviews\")\n",
        "# tar.close()\n",
        "\n",
        "# # Load reviews and labels\n",
        "# reviews = []\n",
        "# labels = []\n",
        "# base_dir = \"movie_reviews/txt_sentoken\"\n",
        "# pos_dir = os.path.join(base_dir, \"pos\")\n",
        "# for filename in os.listdir(pos_dir):\n",
        "#     if filename.endswith(\".txt\"):\n",
        "#         with open(os.path.join(pos_dir, filename), \"r\", encoding=\"utf-8\") as file:\n",
        "#             review = file.read().strip()\n",
        "#             reviews.append(review)\n",
        "#             labels.append(1)\n",
        "# neg_dir = os.path.join(base_dir, \"neg\")\n",
        "# for filename in os.listdir(neg_dir):\n",
        "#     if filename.endswith(\".txt\"):\n",
        "#         with open(os.path.join(neg_dir, filename), \"r\", encoding=\"utf-8\") as file:\n",
        "#             review = file.read().strip()\n",
        "#             reviews.append(review)\n",
        "#             labels.append(0)\n",
        "\n",
        "# # Create CSV file\n",
        "# print(\"Creating CSV file...\")\n",
        "# data = {\"review\": reviews, \"sentiment\": labels}\n",
        "# df = pd.DataFrame(data)\n",
        "# df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
        "# print(f\"Dataset saved to {output_csv}\")\n",
        "# shutil.rmtree(\"movie_reviews\")\n",
        "# print(\"Cleaned up temporary files\")\n",
        "\n",
        "# # Text preprocessing functions\n",
        "# def remove_punctuation(text):\n",
        "#     return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# def normalize_text(text):\n",
        "#     normalization_map = {\n",
        "#         'u': 'you',\n",
        "#         'ur': 'your',\n",
        "#         'r': 'are',\n",
        "#         'b4': 'before',\n",
        "#         'gr8': 'great',\n",
        "#         'gud': 'good',\n",
        "#         'pls': 'please',\n",
        "#         'plz': 'please',\n",
        "#         'thx': 'thanks',\n",
        "#         'l8r': 'later',\n",
        "#         'msg': 'message',\n",
        "#         'btw': 'by the way',\n",
        "#         'idk': 'i do not know',\n",
        "#         'imo': 'in my opinion'\n",
        "#     }\n",
        "#     words = text.split()\n",
        "#     return ' '.join([normalization_map.get(word, word) for word in words])\n",
        "\n",
        "# def stem_text(text):\n",
        "#     stemmer = PorterStemmer()\n",
        "#     stop_words = set(stopwords.words('english')) - {'was'}\n",
        "#     tokens = text.split()\n",
        "#     return ' '.join([stemmer.stem(token) for token in tokens if token not in stop_words])\n",
        "\n",
        "# def remove_word_duplicates(text):\n",
        "#     words = word_tokenize(text)\n",
        "#     seen = set()\n",
        "#     new_words = []\n",
        "#     for word in words:\n",
        "#         if word.lower() not in seen:\n",
        "#             seen.add(word.lower())\n",
        "#             new_words.append(word)\n",
        "#     return ' '.join(new_words)\n",
        "\n",
        "# def preprocess_text(text):\n",
        "#     text = text.lower()\n",
        "#     text = remove_punctuation(text)\n",
        "#     text = normalize_text(text)\n",
        "#     text = ' '.join([word for word in text.split() if word not in (set(stopwords.words('english')) - {'was'})])\n",
        "#     text = remove_word_duplicates(text)\n",
        "#     lemmatizer = WordNetLemmatizer()\n",
        "#     text = ' '.join([lemmatizer.lemmatize(word) for word in nltk.word_tokenize(text)])\n",
        "#     text = stem_text(text)\n",
        "#     return text\n",
        "\n",
        "# # Preprocess data\n",
        "# df['review'] = df['review'].apply(preprocess_text)\n",
        "# df['sentiment'] = df['sentiment'].astype(str)\n",
        "\n",
        "# # Split data\n",
        "# X = df['review'].astype(str).tolist()\n",
        "# y = df['sentiment']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Vectorize and select features (aligned with traditional ML preprocessing from notebook)\n",
        "# # Note: Using TF-IDF and chi2 feature selection as they are effective for LinearSVC and simpler than deep learning preprocessing (tokenization, padding, embeddings)\n",
        "# vectorizer = TfidfVectorizer(max_features=10000)\n",
        "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "# X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# selector = SelectKBest(chi2, k=5000)\n",
        "# X_train_tfidf = selector.fit_transform(X_train_tfidf, y_train)\n",
        "# X_test_tfidf = selector.transform(X_test_tfidf)\n",
        "\n",
        "# # Train model (LinearSVC chosen based on notebook's conclusion that traditional models outperform deep learning models)\n",
        "# # Notebook insight: Deep learning models (CNN, GRU) overfit, while LinearSVC generalizes better with simpler preprocessing\n",
        "# model = LinearSVC(C=1, random_state=42, class_weight='balanced', max_iter=10000)\n",
        "# model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# # Evaluate model\n",
        "# y_pred = model.predict(X_test_tfidf)\n",
        "# print(f\"Test Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "\n",
        "# # Debug vocabulary and feature weights\n",
        "# print(\"Vocabulary contains 'good':\", \"good\" in vectorizer.vocabulary_)\n",
        "# print(\"Vocabulary contains 'movi':\", \"movi\" in vectorizer.vocabulary_)\n",
        "# selected_features = vectorizer.get_feature_names_out()[selector.get_support()]\n",
        "# print(\"Selected features contain 'good':\", \"good\" in selected_features)\n",
        "# print(\"Selected features contain 'movi':\", \"movi\" in selected_features)\n",
        "# feature_weights = model.coef_[0]\n",
        "# feature_importance = dict(zip(selected_features, feature_weights))\n",
        "# print(\"Weight for 'good':\", feature_importance.get(\"good\", \"Not found\"))\n",
        "# print(\"Weight for 'movi':\", feature_importance.get(\"movi\", \"Not found\"))\n",
        "\n",
        "# # Save model, vectorizer, and selector\n",
        "# joblib.dump(model, 'linear_svc_model.pkl')\n",
        "# joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
        "# joblib.dump(selector, 'chi2_selector.pkl')\n",
        "# print(\"Model, vectorizer, and selector saved.\")\n",
        "\n",
        "# # HTML template (unchanged)\n",
        "# html_template = \"\"\"\n",
        "# <!DOCTYPE html>\n",
        "# <html lang=\"en\">\n",
        "# <head>\n",
        "#     <meta charset=\"UTF-8\">\n",
        "#     <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "#     <title>Sentiment Analysis</title>\n",
        "#     <link rel=\"stylesheet\" href=\"/static/style.css\">\n",
        "# </head>\n",
        "# <body>\n",
        "#     <div class=\"header\">\n",
        "#         <h2>Sentiment Analysis of Movie Reviews</h2>\n",
        "#     </div>\n",
        "#     <div class=\"parent\">\n",
        "#         <div class=\"collection\">\n",
        "#             <p>Please enter your text in English for analysis</p>\n",
        "#             <form onsubmit=\"analyzeReview(event)\">\n",
        "#                 <textarea id=\"reviewInput\" placeholder=\"Type here...\" cols=\"70\" rows=\"10\"></textarea>\n",
        "#                 <button type=\"submit\">Analyze</button>\n",
        "#             </form>\n",
        "#             <div id=\"result\" class=\"result\"></div>\n",
        "#             <div id=\"processed\" class=\"processed\"></div>\n",
        "#         </div>\n",
        "#     </div>\n",
        "\n",
        "#     <script>\n",
        "#         // Auto-resize textarea\n",
        "#         const textarea = document.getElementById('reviewInput');\n",
        "#         textarea.addEventListener('input', function () {\n",
        "#             this.style.height = 'auto';\n",
        "#             this.style.height = `${this.scrollHeight}px`;\n",
        "#         });\n",
        "\n",
        "#         // Handle form submission and send request to backend\n",
        "#         async function analyzeReview(event) {\n",
        "#             event.preventDefault();\n",
        "#             const review = document.getElementById('reviewInput').value.trim();\n",
        "#             const resultDiv = document.getElementById('result');\n",
        "#             const processedDiv = document.getElementById('processed');\n",
        "\n",
        "#             if (!review) {\n",
        "#                 resultDiv.innerHTML = '<p class=\"error\">Please enter a review.</p>';\n",
        "#                 processedDiv.innerHTML = '';\n",
        "#                 return;\n",
        "#             }\n",
        "\n",
        "#             resultDiv.innerHTML = '<p>Analyzing...</p>';\n",
        "#             processedDiv.innerHTML = '';\n",
        "\n",
        "#             try {\n",
        "#                 const response = await fetch('/analyze', {\n",
        "#                     method: 'POST',\n",
        "#                     headers: {\n",
        "#                         'Content-Type': 'application/json',\n",
        "#                     },\n",
        "#                     body: JSON.stringify({ review: review }),\n",
        "#                 });\n",
        "\n",
        "#                 const data = await response.json();\n",
        "\n",
        "#                 if (response.ok) {\n",
        "#                     resultDiv.innerHTML = `<p class=\"success\">Sentiment: ${data.sentiment}</p>`;\n",
        "#                     processedDiv.innerHTML = `<p class=\"processed-text\"><strong>Processed Review:</strong> ${data.processed_text}</p>`;\n",
        "#                 } else {\n",
        "#                     resultDiv.innerHTML = `<p class=\"error\">Error: ${data.error}</p>`;\n",
        "#                     processedDiv.innerHTML = '';\n",
        "#                 }\n",
        "#             } catch (error) {\n",
        "#                 resultDiv.innerHTML = '<p class=\"error\">Error: Unable to connect to the server.</p>';\n",
        "#                 processedDiv.innerHTML = '';\n",
        "#             }\n",
        "#         }\n",
        "#     </script>\n",
        "# </body>\n",
        "# </html>\n",
        "# \"\"\"\n",
        "\n",
        "# # CSS content (unchanged)\n",
        "# css_content = \"\"\"\n",
        "# * {\n",
        "#     margin: 0;\n",
        "#     padding: 0;\n",
        "#     box-sizing: border-box;\n",
        "# }\n",
        "\n",
        "# body {\n",
        "#     background-color: #ffd9e8;\n",
        "#     color: #333;\n",
        "#     font-family: Arial, sans-serif;\n",
        "#     font-size: 17px;\n",
        "# }\n",
        "\n",
        "# .header {\n",
        "#     width: 100%;\n",
        "#     height: 100px;\n",
        "#     background-color: #F564A9;\n",
        "#     padding-top: 25px;\n",
        "# }\n",
        "\n",
        "# .header h2 {\n",
        "#     text-transform: capitalize;\n",
        "#     font-size: 33px;\n",
        "#     text-align: center;\n",
        "#     color: white;\n",
        "# }\n",
        "\n",
        "# .parent {\n",
        "#     margin-top: 50px;\n",
        "#     display: flex;\n",
        "#     align-items: center;\n",
        "#     justify-content: center;\n",
        "# }\n",
        "\n",
        "# .collection {\n",
        "#     background-color: #F564A9;\n",
        "#     width: 90%;\n",
        "#     max-width: 600px;\n",
        "#     min-height: 400px;\n",
        "#     display: flex;\n",
        "#     flex-direction: column;\n",
        "#     justify-content: center;\n",
        "#     align-items: center;\n",
        "#     border-radius: 20px;\n",
        "#     padding: 20px;\n",
        "#     box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
        "# }\n",
        "\n",
        "# .collection p {\n",
        "#     text-transform: capitalize;\n",
        "#     font-size: 20px;\n",
        "#     text-align: center;\n",
        "#     color: white;\n",
        "#     margin-bottom: 20px;\n",
        "# }\n",
        "\n",
        "# .collection textarea {\n",
        "#     background-color: #ffd9e8;\n",
        "#     margin-top: 10px;\n",
        "#     width: 100%;\n",
        "#     min-height: 150px;\n",
        "#     resize: vertical;\n",
        "#     border: none;\n",
        "#     border-radius: 10px;\n",
        "#     padding: 15px;\n",
        "#     font-size: 17px;\n",
        "#     color: #333;\n",
        "#     box-sizing: border-box;\n",
        "# }\n",
        "\n",
        "# .collection textarea::placeholder {\n",
        "#     color: #c90865;\n",
        "#     text-align: left;\n",
        "#     opacity: 1;\n",
        "# }\n",
        "\n",
        "# .collection button {\n",
        "#     width: 150px;\n",
        "#     height: 40px;\n",
        "#     border: none;\n",
        "#     border-radius: 10px;\n",
        "#     font-size: 20px;\n",
        "#     color: #c90865;\n",
        "#     background-color: #ffd9e8;\n",
        "#     cursor: pointer;\n",
        "#     transition: background-color 0.3s;\n",
        "#     margin-top: 20px;\n",
        "# }\n",
        "\n",
        "# .result {\n",
        "#     margin-top: 20px;\n",
        "#     text-align: center;\n",
        "#     min-height: 30px;\n",
        "# }\n",
        "\n",
        "# .processed {\n",
        "#     margin-top: 10px;\n",
        "#     text-align: center;\n",
        "#     min-height: 30px;\n",
        "# }\n",
        "\n",
        "# .processed-text {\n",
        "#     color: #fff;\n",
        "#     font-size: 16px;\n",
        "#     background-color: #c90865;\n",
        "#     padding: 10px;\n",
        "#     border-radius: 5px;\n",
        "#     word-wrap: break-word;\n",
        "#     max-width: 100%;\n",
        "# }\n",
        "\n",
        "# .success {\n",
        "#     color: #28a745;\n",
        "#     font-weight: bold;\n",
        "# }\n",
        "\n",
        "# .error {\n",
        "#     color: #dc3545;\n",
        "#     font-weight: bold;\n",
        "# }\n",
        "# \"\"\"\n",
        "\n",
        "# # Save CSS file\n",
        "# os.makedirs('static', exist_ok=True)\n",
        "# with open('static/style.css', 'w') as f:\n",
        "#     f.write(css_content)\n",
        "\n",
        "# # Initialize Flask app\n",
        "# app = Flask(__name__)\n",
        "\n",
        "# # Load model, vectorizer, and selector\n",
        "# model = joblib.load('linear_svc_model.pkl')\n",
        "# vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
        "# selector = joblib.load('chi2_selector.pkl')\n",
        "\n",
        "# # Flask routes\n",
        "# @app.route('/', methods=['GET'])\n",
        "# def index():\n",
        "#     return render_template_string(html_template)\n",
        "\n",
        "# @app.route('/analyze', methods=['POST'])\n",
        "# def analyze():\n",
        "#     data = request.get_json()\n",
        "#     review = data.get('review', '').strip()\n",
        "#     logging.info(f\"Received review: {review}\")\n",
        "#     if not review:\n",
        "#         return jsonify({'error': 'Please enter a review.'}), 400\n",
        "#     processed_text = preprocess_text(review)\n",
        "#     logging.info(f\"Processed text: {processed_text}\")\n",
        "#     text_tfidf = vectorizer.transform([processed_text])\n",
        "#     text_tfidf_selected = selector.transform(text_tfidf)\n",
        "#     prediction = model.predict(text_tfidf_selected)[0]\n",
        "#     logging.info(f\"Prediction: {prediction}\")\n",
        "#     sentiment = \"Positive üòÑ‚úîÔ∏è\" if prediction == \"1\" else \"Negative üòî‚ùå\"\n",
        "#     return jsonify({\n",
        "#         'sentiment': sentiment,\n",
        "#         'processed_text': processed_text\n",
        "#     })\n",
        "\n",
        "# # Function to kill process on port\n",
        "# def kill_process_on_port(port):\n",
        "#     for proc in psutil.process_iter(['pid', 'name']):\n",
        "#         try:\n",
        "#             for conn in proc.connections(kind='inet'):\n",
        "#                 if conn.laddr.port == port:\n",
        "#                     print(f\"Killing process {proc.pid} on port {port}\")\n",
        "#                     proc.kill()\n",
        "#                     return True\n",
        "#         except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n",
        "#             continue\n",
        "#     return False\n",
        "\n",
        "# # Start ngrok and Flask server\n",
        "# ngrok.set_auth_token('2x9G2X34klXZC2VDcx4AFxbvAPm_2DCdLrALRo27kMQxwq55u')\n",
        "# PORT = 5001\n",
        "# try:\n",
        "#     ngrok.kill()\n",
        "#     kill_process_on_port(PORT)\n",
        "#     public_url = ngrok.connect(PORT).public_url\n",
        "#     print(f\"Public URL: {public_url}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Error starting ngrok: {e}\")\n",
        "#     print(\"Please ensure no other ngrok sessions are active and try again. Check https://dashboard.ngrok.com/agents\")\n",
        "\n",
        "# def run_app():\n",
        "#     print(f\"Starting Flask server on port {PORT}...\")\n",
        "#     app.run(host='0.0.0.0', port=PORT, use_reloader=False)\n",
        "#     print(f\"Flask server running on port {PORT}.\")\n",
        "\n",
        "# threading.Thread(target=run_app, daemon=True).start()\n",
        "\n",
        "# # Check server status\n",
        "# time.sleep(2)\n",
        "# try:\n",
        "#     response = requests.get(f\"{public_url}\")\n",
        "#     print(\"Server is up and running!\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Server check failed: {e}\")\n",
        "#     print(\"The Flask server may not have started correctly. Please restart the cell or runtime.\")\n",
        "\n",
        "# # Test specific input\n",
        "# test_review = \"movie was good\"\n",
        "# processed_test = preprocess_text(test_review)\n",
        "# print(f\"Processed test review: {processed_test}\")\n",
        "# test_tfidf = vectorizer.transform([processed_test])\n",
        "# test_tfidf_selected = selector.transform(test_tfidf)\n",
        "# test_prediction = model.predict(test_tfidf_selected)[0]\n",
        "# print(f\"Prediction for 'movie was good': {test_prediction}\")\n",
        "# print(f\"Sentiment: {'Positive üòÑ‚úîÔ∏è' if test_prediction == '1' else 'Negative üòî‚ùå'}\")"
      ],
      "metadata": {
        "id": "IBEeg4X-ilO2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import requests\n",
        "import tarfile\n",
        "from io import BytesIO\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "from flask import Flask, request, render_template_string, jsonify\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import psutil\n",
        "import shutil\n",
        "import logging\n",
        "\n",
        "# Set up logging for Flask/Werkzeug to suppress INFO logs\n",
        "logging.getLogger('werkzeug').setLevel(logging.WARNING)  # Changed from INFO to WARNING\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Download and extract dataset\n",
        "url = \"http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\"\n",
        "output_csv = \"data_set.csv\"\n",
        "print(\"Downloading dataset...\")\n",
        "response = requests.get(url)\n",
        "if response.status_code != 200:\n",
        "    raise Exception(\"Failed to download the dataset\")\n",
        "print(\"Extracting dataset...\")\n",
        "tar = tarfile.open(fileobj=BytesIO(response.content), mode=\"r:gz\")\n",
        "tar.extractall(path=\"movie_reviews\")\n",
        "tar.close()\n",
        "\n",
        "# Load reviews and labels\n",
        "reviews = []\n",
        "labels = []\n",
        "base_dir = \"movie_reviews/txt_sentoken\"\n",
        "pos_dir = os.path.join(base_dir, \"pos\")\n",
        "for filename in os.listdir(pos_dir):\n",
        "    if filename.endswith(\".txt\"):\n",
        "        with open(os.path.join(pos_dir, filename), \"r\", encoding=\"utf-8\") as file:\n",
        "            review = file.read().strip()\n",
        "            reviews.append(review)\n",
        "            labels.append(1)\n",
        "neg_dir = os.path.join(base_dir, \"neg\")\n",
        "for filename in os.listdir(neg_dir):\n",
        "    if filename.endswith(\".txt\"):\n",
        "        with open(os.path.join(neg_dir, filename), \"r\", encoding=\"utf-8\") as file:\n",
        "            review = file.read().strip()\n",
        "            reviews.append(review)\n",
        "            labels.append(0)\n",
        "\n",
        "# Create CSV file\n",
        "print(\"Creating CSV file...\")\n",
        "data = {\"review\": reviews, \"sentiment\": labels}\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
        "print(f\"Dataset saved to {output_csv}\")\n",
        "shutil.rmtree(\"movie_reviews\")\n",
        "print(\"Cleaned up temporary files\")\n",
        "\n",
        "# Text preprocessing functions\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "def normalize_text(text):\n",
        "    normalization_map = {\n",
        "        'u': 'you',\n",
        "        'ur': 'your',\n",
        "        'r': 'are',\n",
        "        'b4': 'before',\n",
        "        'gr8': 'great',\n",
        "        'gud': 'good',\n",
        "        'pls': 'please',\n",
        "        'plz': 'please',\n",
        "        'thx': 'thanks',\n",
        "        'l8r': 'later',\n",
        "        'msg': 'message',\n",
        "        'btw': 'by the way',\n",
        "        'idk': 'i do not know',\n",
        "        'imo': 'in my opinion'\n",
        "    }\n",
        "    words = text.split()\n",
        "    return ' '.join([normalization_map.get(word, word) for word in words])\n",
        "\n",
        "def stem_text(text):\n",
        "    stemmer = PorterStemmer()\n",
        "    stop_words = set(stopwords.words('english')) - {'was'}\n",
        "    tokens = text.split()\n",
        "    return ' '.join([stemmer.stem(token) for token in tokens if token not in stop_words])\n",
        "\n",
        "def remove_word_duplicates(text):\n",
        "    words = word_tokenize(text)\n",
        "    seen = set()\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word.lower() not in seen:\n",
        "            seen.add(word.lower())\n",
        "            new_words.append(word)\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = remove_punctuation(text)\n",
        "    text = normalize_text(text)\n",
        "    text = ' '.join([word for word in text.split() if word not in (set(stopwords.words('english')) - {'was'})])\n",
        "    text = remove_word_duplicates(text)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text = ' '.join([lemmatizer.lemmatize(word) for word in nltk.word_tokenize(text)])\n",
        "    text = stem_text(text)\n",
        "    return text\n",
        "\n",
        "# Preprocess data\n",
        "df['review'] = df['review'].apply(preprocess_text)\n",
        "df['sentiment'] = df['sentiment'].astype(str)\n",
        "\n",
        "# Split data\n",
        "X = df['review'].astype(str).tolist()\n",
        "y = df['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize and select features\n",
        "vectorizer = TfidfVectorizer(max_features=10000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "selector = SelectKBest(chi2, k=5000)\n",
        "X_train_tfidf = selector.fit_transform(X_train_tfidf, y_train)\n",
        "X_test_tfidf = selector.transform(X_test_tfidf)\n",
        "\n",
        "# Train model\n",
        "model = LinearSVC(C=1, random_state=42, class_weight='balanced', max_iter=10000)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "\n",
        "# Debug vocabulary and feature weights\n",
        "print(\"Vocabulary contains 'good':\", \"good\" in vectorizer.vocabulary_)\n",
        "print(\"Vocabulary contains 'movi':\", \"movi\" in vectorizer.vocabulary_)\n",
        "selected_features = vectorizer.get_feature_names_out()[selector.get_support()]\n",
        "print(\"Selected features contain 'good':\", \"good\" in selected_features)\n",
        "print(\"Selected features contain 'movi':\", \"movi\" in selected_features)\n",
        "feature_weights = model.coef_[0]\n",
        "feature_importance = dict(zip(selected_features, feature_weights))\n",
        "print(\"Weight for 'good':\", feature_importance.get(\"good\", \"Not found\"))\n",
        "print(\"Weight for 'movi':\", feature_importance.get(\"movi\", \"Not found\"))\n",
        "\n",
        "# Save model, vectorizer, and selector\n",
        "joblib.dump(model, 'linear_svc_model.pkl')\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
        "joblib.dump(selector, 'chi2_selector.pkl')\n",
        "print(\"Model, vectorizer, and selector saved.\")\n",
        "\n",
        "# HTML template\n",
        "html_template = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Sentiment Analysis</title>\n",
        "    <link rel=\"stylesheet\" href=\"/static/style.css\">\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"header\">\n",
        "        <h2>Sentiment Analysis of Movie Reviews</h2>\n",
        "    </div>\n",
        "    <div class=\"parent\">\n",
        "        <div class=\"collection\">\n",
        "            <p>Please enter your text in English for analysis</p>\n",
        "            <form onsubmit=\"analyzeReview(event)\">\n",
        "                <textarea id=\"reviewInput\" placeholder=\"Type here...\" cols=\"70\" rows=\"10\"></textarea>\n",
        "                <button type=\"submit\">Analyze</button>\n",
        "            </form>\n",
        "            <div id=\"result\" class=\"result\"></div>\n",
        "            <div id=\"processed\" class=\"processed\"></div>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        // Auto-resize textarea\n",
        "        const textarea = document.getElementById('reviewInput');\n",
        "        textarea.addEventListener('input', function () {\n",
        "            this.style.height = 'auto';\n",
        "            this.style.height = `${this.scrollHeight}px`;\n",
        "        });\n",
        "\n",
        "        // Handle form submission and send request to backend\n",
        "        async function analyzeReview(event) {\n",
        "            event.preventDefault();\n",
        "            const review = document.getElementById('reviewInput').value.trim();\n",
        "            const resultDiv = document.getElementById('result');\n",
        "            const processedDiv = document.getElementById('processed');\n",
        "\n",
        "            if (!review) {\n",
        "                resultDiv.innerHTML = '<p class=\"error\">Please enter a review.</p>';\n",
        "                processedDiv.innerHTML = '';\n",
        "                return;\n",
        "            }\n",
        "\n",
        "            resultDiv.innerHTML = '<p>Analyzing...</p>';\n",
        "            processedDiv.innerHTML = '';\n",
        "\n",
        "            try {\n",
        "                const response = await fetch('/analyze', {\n",
        "                    method: 'POST',\n",
        "                    headers: {\n",
        "                        'Content-Type': 'application/json',\n",
        "                    },\n",
        "                    body: JSON.stringify({ review: review }),\n",
        "                });\n",
        "\n",
        "                const data = await response.json();\n",
        "\n",
        "                if (response.ok) {\n",
        "                    resultDiv.innerHTML = `<p class=\"success\">Sentiment: ${data.sentiment}</p>`;\n",
        "                    processedDiv.innerHTML = `<p class=\"processed-text\"><strong>Processed Review:</strong> ${data.processed_text}</p>`;\n",
        "                } else {\n",
        "                    resultDiv.innerHTML = `<p class=\"error\">Error: ${data.error}</p>`;\n",
        "                    processedDiv.innerHTML = '';\n",
        "                }\n",
        "            } catch (error) {\n",
        "                resultDiv.innerHTML = `<p class=\"error\">Error: Unable to connect to the server.</p>`;\n",
        "                processedDiv.innerHTML = '';\n",
        "            }\n",
        "        }\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# CSS content\n",
        "css_content = \"\"\"\n",
        "* {\n",
        "    margin: 0;\n",
        "    padding: 0;\n",
        "    box-sizing: border-box;\n",
        "}\n",
        "\n",
        "body {\n",
        "    background-color: #ffd9e8;\n",
        "    color: #333;\n",
        "    font-family: Arial, sans-serif;\n",
        "    font-size: 17px;\n",
        "}\n",
        "\n",
        ".header {\n",
        "    width: 100%;\n",
        "    height: 100px;\n",
        "    background-color: #F564A9;\n",
        "    padding-top: 25px;\n",
        "}\n",
        "\n",
        ".header h2 {\n",
        "    text-transform: capitalize;\n",
        "    font-size: 33px;\n",
        "    text-align: center;\n",
        "    color: white;\n",
        "}\n",
        "\n",
        ".parent {\n",
        "    margin-top: 50px;\n",
        "    display: flex;\n",
        "    align-items: center;\n",
        "    justify-content: center;\n",
        "}\n",
        "\n",
        ".collection {\n",
        "    background-color: #F564A9;\n",
        "    width: 90%;\n",
        "    max-width: 600px;\n",
        "    min-height: 400px;\n",
        "    display: flex;\n",
        "    flex-direction: column;\n",
        "    justify-content: center;\n",
        "    align-items: center;\n",
        "    border-radius: 20px;\n",
        "    padding: 20px;\n",
        "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
        "}\n",
        "\n",
        ".collection p {\n",
        "    text-transform: capitalize;\n",
        "    font-size: 20px;\n",
        "    text-align: center;\n",
        "    color: white;\n",
        "    margin-bottom: 20px;\n",
        "}\n",
        "\n",
        ".collection textarea {\n",
        "    background-color: #ffd9e8;\n",
        "    margin-top: 10px;\n",
        "    width: 100%;\n",
        "    min-height: 150px;\n",
        "    resize: vertical;\n",
        "    border: none;\n",
        "    border-radius: 10px;\n",
        "    padding: 15px;\n",
        "    font-size: 17px;\n",
        "    color: #333;\n",
        "    box-sizing: border-box;\n",
        "}\n",
        "\n",
        ".collection textarea::placeholder {\n",
        "    color: #c90865;\n",
        "    text-align: left;\n",
        "    opacity: 1;\n",
        "}\n",
        "\n",
        ".collection button {\n",
        "    width: 150px;\n",
        "    height: 40px;\n",
        "    border: none;\n",
        "    border-radius: 10px;\n",
        "    font-size: 20px;\n",
        "    color: #c90865;\n",
        "    background-color: #ffd9e8;\n",
        "    cursor: pointer;\n",
        "    transition: background-color 0.3s;\n",
        "    margin-top: 20px;\n",
        "}\n",
        "\n",
        ".result {\n",
        "    margin-top: 20px;\n",
        "    text-align: center;\n",
        "    min-height: 30px;\n",
        "}\n",
        "\n",
        ".processed {\n",
        "    margin-top: 10px;\n",
        "    text-align: center;\n",
        "    min-height: 30px;\n",
        "}\n",
        "\n",
        ".processed-text {\n",
        "    color: #fff;\n",
        "    font-size: 16px;\n",
        "    background-color: #c90865;\n",
        "    padding: 10px;\n",
        "    border-radius: 5px;\n",
        "    word-wrap: break-word;\n",
        "    max-width: 100%;\n",
        "}\n",
        "\n",
        ".success {\n",
        "    color: #28a745;\n",
        "    font-weight: bold;\n",
        "}\n",
        "\n",
        ".error {\n",
        "    color: #dc3545;\n",
        "    font-weight: bold;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Save CSS file\n",
        "os.makedirs('static', exist_ok=True)\n",
        "with open('static/style.css', 'w') as f:\n",
        "    f.write(css_content)\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load model, vectorizer, and selector\n",
        "model = joblib.load('linear_svc_model.pkl')\n",
        "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
        "selector = joblib.load('chi2_selector.pkl')\n",
        "\n",
        "# Flask routes\n",
        "@app.route('/', methods=['GET'])\n",
        "def index():\n",
        "    return render_template_string(html_template)\n",
        "\n",
        "@app.route('/analyze', methods=['POST'])\n",
        "def analyze():\n",
        "    data = request.get_json()\n",
        "    review = data.get('review', '').strip()\n",
        "    logging.info(f\"Received review: {review}\")\n",
        "    if not review:\n",
        "        return jsonify({'error': 'Please enter a review.'}), 400\n",
        "    processed_text = preprocess_text(review)\n",
        "    logging.info(f\"Processed text: {processed_text}\")\n",
        "    text_tfidf = vectorizer.transform([processed_text])\n",
        "    text_tfidf_selected = selector.transform(text_tfidf)\n",
        "    prediction = model.predict(text_tfidf_selected)[0]\n",
        "    logging.info(f\"Prediction: {prediction}\")\n",
        "    sentiment = \"Positive üòÑ‚úîÔ∏è\" if prediction == \"1\" else \"Negative üòî‚ùå\"\n",
        "    return jsonify({\n",
        "        'sentiment': sentiment,\n",
        "        'processed_text': processed_text\n",
        "    })\n",
        "\n",
        "# Function to kill process on port\n",
        "def kill_process_on_port(port):\n",
        "    for proc in psutil.process_iter(['pid', 'name']):\n",
        "        try:\n",
        "            for conn in proc.connections(kind='inet'):\n",
        "                if conn.laddr.port == port:\n",
        "                    print(f\"Killing process {proc.pid} on port {port}\")\n",
        "                    proc.kill()\n",
        "                    return True\n",
        "        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n",
        "            continue\n",
        "    return False\n",
        "\n",
        "# Start ngrok and Flask server\n",
        "ngrok.set_auth_token('2x9G2X34klXZC2VDcx4AFxbvAPm_2DCdLrALRo27kMQxwq55u')\n",
        "PORT = 5001\n",
        "try:\n",
        "    ngrok.kill()\n",
        "    kill_process_on_port(PORT)\n",
        "    public_url = ngrok.connect(PORT).public_url\n",
        "    print(f\"Public URL: {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error starting ngrok: {e}\")\n",
        "    print(\"Please ensure no other ngrok sessions are active and try again. Check https://dashboard.ngrok.com/agents\")\n",
        "\n",
        "def run_app():\n",
        "    print(f\"Starting Flask server on port {PORT}...\")\n",
        "    app.run(host='0.0.0.0', port=PORT, use_reloader=False)\n",
        "\n",
        "threading.Thread(target=run_app, daemon=True).start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcDBCJOmkmpF",
        "outputId": "8d337261-213c-45fa-f272-a20f94bb5d27"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Extracting dataset...\n",
            "Creating CSV file...\n",
            "Dataset saved to data_set.csv\n",
            "Cleaned up temporary files\n",
            "Test Accuracy: 0.85\n",
            "Vocabulary contains 'good': True\n",
            "Vocabulary contains 'movi': True\n",
            "Selected features contain 'good': False\n",
            "Selected features contain 'movi': False\n",
            "Weight for 'good': Not found\n",
            "Weight for 'movi': Not found\n",
            "Model, vectorizer, and selector saved.\n",
            "Public URL: https://078e-34-82-214-188.ngrok-free.app\n",
            "Starting Flask server on port 5001...\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}